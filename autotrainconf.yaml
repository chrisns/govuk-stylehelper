
# task: llm-orpo
task: llm-sft
base_model: "meta-llama/llama-2-7b-chat-hf"
project_name: govuk-stylehelper
log: tensorboard
backend: local

data:
  path: data/
  chat_template: null
  train_split: train
  valid_split: null

  column_mapping:
    text_column: text
    # rejected_text_column: rejected_text
    prompt_text_column: prompt

params:
  block_size: 1024
  lr: 0.0002
  warmup_ratio: 0.1
  weight_decay: 0.01
  epochs: 1
  batch_size: 2
  gradient_accumulation: 4
  # mixed_precision: fp16
  peft: True
  quantization: none
  lora_r: 8
  lora_alpha: 32
  lora_dropout: 0.05
  unsloth: False
